{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovieReview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx-cd90mw_5b",
        "colab_type": "text"
      },
      "source": [
        "# Movie Review Classification\n",
        "### CS 175\n",
        "\n",
        "##### Darren Lim\n",
        "##### Justin Lonh\n",
        "##### Jerson Villanueva\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhLJMDLyneeH",
        "colab_type": "text"
      },
      "source": [
        "## IMPORT\n",
        "\n",
        "Import the necessary libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFJYj7aZyFZx",
        "colab_type": "code",
        "outputId": "1d81bec3-3e87-4d21-d4cc-79566b115a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "pip install tensorflow_datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1)\n",
            "Requirement already satisfied: absl-py in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (3.11.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.1.1)\n",
            "Requirement already satisfied: wrapt in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.12.0)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.1.0)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from tensorflow_datasets) (1.18.1)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.3.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.21.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (1.25.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.6.1->tensorflow_datasets) (45.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.51.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnV32QJPwyv3",
        "colab_type": "code",
        "outputId": "63320d4f-9ca9-40b8-ce6f-1f11ca3c52d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from string import punctuation\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from numpy import array\n",
        "from numpy import zeros\n",
        "from numpy import asarray\n",
        "import gensim \n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#from tensorflow.keras import backend\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.models import Sequential as Sequential\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Dropout as Dropout\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Embedding as Embedding\n",
        "from tensorflow.keras.layers import Conv1D as Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D as MaxPooling1D\n",
        "#from tensorflow.layers.convolutional import MaxPooling1D\n",
        "\n",
        "from tensorflow.keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r67AZXJZZRWT",
        "colab_type": "text"
      },
      "source": [
        "We stored our Kaggle dataset into our google drive, so we mount our drive first to have access to the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDy7TaHrZ1VS",
        "colab_type": "text"
      },
      "source": [
        "## LOAD DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biZOiEvaywL6",
        "colab_type": "code",
        "outputId": "c41ea738-f476-49bf-c76a-da78b479f971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# mount google drive to get movie review data (uploaded to google drive)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtWagLOoy0Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = '/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/neg'\n",
        "directory2 = '/content/drive/My Drive/CS175/imdb/train/pos'\n",
        "\n",
        "# example how to use imdb dataset\n",
        "# this code gets the training split from imdb dataset, shuffles it, splits into batches of 32 reviews\n",
        "# then for each batch, zips together label values and text values, and prints them\n",
        "# for vocab creation or if you don't need labels, can just iterate through bat['text'].numpy() to get text\n",
        "\n",
        "imdb_train = tfds.load(name=\"imdb_reviews\", split=\"train\")\n",
        "imdb_train = imdb_train.shuffle(1024).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "vocab = None\n",
        "imdbVocab = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHIieBl4bfNA",
        "colab_type": "text"
      },
      "source": [
        "## TOKENIZE VOCAB WORDS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GduIzAyxnrfj",
        "colab_type": "text"
      },
      "source": [
        "The following code blocks will clean and create a list of vocabulary from the review text files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRL_D5WEiJeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Following code blocks are from https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "# on cleaning and recovering vocabulary from the txt files\n",
        "\n",
        "def ReadFile(filename):\n",
        "  file = None\n",
        "  with open(filename) as f:\n",
        "    file = f.read()\n",
        "  return file\n",
        "\n",
        "def clean_file(doc):\n",
        "  # split into tokens by white space\n",
        "  tokens = doc.split()\n",
        "  # remove punctuation from each token\\\n",
        "  table = str.maketrans('', '', punctuation)\n",
        "  tokens = [w.translate(table) for w in tokens]\n",
        "  # remove remaining tokens that are not alphabetic\n",
        "  tokens = [word for word in tokens if word.isalpha()]\n",
        "  # filter out stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [w for w in tokens if not w in stop_words]\n",
        "  # filter out short tokens\n",
        "  tokens = [word for word in tokens if len(word) > 1 and word != 'br']\n",
        "  stemmer = PorterStemmer()\n",
        "  tokens = [stemmer.stem(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "# load doc and add to vocab\n",
        "def add_doc_to_vocab(filename, vocab):\n",
        "\t# load doc\n",
        "\tdoc = ReadFile(filename)\n",
        "\t# clean doc\n",
        "\ttokens = clean_file(doc)\n",
        "\t# update counts\n",
        "\tvocab.update(tokens)\n",
        "\n",
        "# load all docs in a directory\n",
        "def process_docs(directory, vocab, is_train):\n",
        "\t# walk through all files in the folder\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# skip any reviews in the test set\n",
        "\t\tif is_train and filename.startswith('cv9'):\n",
        "\t\t\tcontinue\n",
        "\t\tif not is_train and not filename.startswith('cv9'):\n",
        "\t\t\tcontinue\n",
        "\t\t# create the full path of the file to open\n",
        "\t\tpath = directory + '/' + filename\n",
        "\t\t# add doc to vocab\n",
        "\t\tadd_doc_to_vocab(path, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfwj7UoLkliQ",
        "colab_type": "code",
        "outputId": "85542f41-0998-4ee2-fbd5-05ba1f173715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "'''\n",
        "This code block grabs all of the vocab words in the neg and pos text files\n",
        "and cleans out the words that occur the least.\n",
        "Bag of words\n",
        "'''\n",
        "# define vocab\n",
        "vocab = Counter()\n",
        "imdbVocab = Counter()\n",
        "# add all docs to vocab\n",
        "neg_directory = '/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/neg'\n",
        "pos_directory = '/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/pos'\n",
        "process_docs(neg_directory, vocab, True)\n",
        "process_docs(pos_directory, vocab, True)\n",
        "\n",
        "# adding imdb reviews to vocab\n",
        "for review in imdb_train:\n",
        "  imdbVocab.update(clean_file(review['text'].numpy().decode('utf-8')))\n",
        "\n",
        "print(\"total vocab kaggle: \", len(vocab))\n",
        "print(\"total vocab imdb: \", len(imdbVocab))\n",
        "\n",
        "# keep tokens with a min occurrence\n",
        "min_occurane = 2\n",
        "tokens = [k for k,c in vocab.items() if c >= min_occurane]\n",
        "imdbTokens = [k for k,c in imdbVocab.items() if c >= min_occurane]\n",
        "\n",
        "print(\"total vocab Kaggle after removing min occurance: \", len(tokens))\n",
        "print(vocab.most_common(50))\n",
        "print(\"total vocab IMDB after removing min occurance: \",len(imdbTokens))\n",
        "print(imdbVocab.most_common(50))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total vocab kaggle:  29581\n",
            "total vocab imdb:  89547\n",
            "total vocab Kaggle after removing min occurance:  17576\n",
            "[('film', 9984), ('movi', 6064), ('one', 5156), ('like', 3597), ('charact', 3439), ('get', 2870), ('make', 2812), ('time', 2608), ('scene', 2376), ('even', 2306), ('play', 2155), ('good', 2141), ('stori', 2092), ('see', 1977), ('would', 1844), ('much', 1825), ('also', 1757), ('go', 1742), ('way', 1683), ('seem', 1662), ('two', 1643), ('end', 1635), ('take', 1625), ('look', 1617), ('first', 1589), ('come', 1588), ('well', 1572), ('work', 1522), ('thing', 1481), ('realli', 1407), ('know', 1402), ('year', 1390), ('plot', 1376), ('perform', 1363), ('littl', 1354), ('life', 1345), ('peopl', 1304), ('love', 1272), ('bad', 1256), ('could', 1248), ('man', 1212), ('show', 1205), ('never', 1201), ('tri', 1192), ('best', 1182), ('new', 1140), ('give', 1137), ('mani', 1130), ('star', 1121), ('doesnt', 1118)]\n",
            "total vocab IMDB after removing min occurance:  39515\n",
            "[('movi', 49597), ('film', 46299), ('the', 45829), ('one', 26668), ('like', 22139), ('time', 15074), ('thi', 15002), ('good', 14760), ('make', 14517), ('get', 14039), ('see', 13823), ('charact', 13805), ('watch', 13629), ('even', 12752), ('stori', 12650), ('would', 12135), ('It', 12074), ('realli', 11664), ('scene', 10233), ('well', 9742), ('look', 9695), ('show', 9627), ('much', 9584), ('peopl', 9224), ('end', 9184), ('also', 9073), ('great', 8998), ('bad', 8952), ('first', 8858), ('think', 8802), ('love', 8723), ('go', 8702), ('play', 8539), ('dont', 8474), ('way', 8457), ('act', 8436), ('there', 8055), ('thing', 8024), ('made', 7990), ('could', 7713), ('say', 7369), ('know', 7367), ('but', 7329), ('seem', 7190), ('and', 7053), ('it', 6773), ('work', 6727), ('mani', 6656), ('two', 6648), ('come', 6623)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZFeeP3cyfQ",
        "colab_type": "code",
        "outputId": "d0d46eb1-e863-4bb6-8f18-7916dc5c045a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "data = '\\n'.join(tokens)\n",
        "# open file\n",
        "with open('/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/vocab.txt', 'w+') as f:\n",
        "  # write text\n",
        "  f.write(data)\n",
        "\n",
        "imdbData = '\\n'.join(imdbTokens)\n",
        "with open('/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/imdbvocab.txt', 'w+') as f:\n",
        "  # write text\n",
        "  f.write(imdbData)\n",
        "\n",
        "'''\n",
        "With this part of the code creating a vocab.txt file, we no longer need to run the block of code before \n",
        "to collect the vocabulary of all the txt files.\n",
        "This next part, we will compare the tokens with the positive and negative reviews\n",
        "and filter the vocab of those text with the vocab.txt we just created.\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWith this part of the code creating a vocab.txt file, we no longer need to run the block of code before \\nto collect the vocabulary of all the txt files.\\nThis next part, we will compare the tokens with the positive and negative reviews\\nand filter the vocab of those text with the vocab.txt we just created.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZfe5Elfbtjq",
        "colab_type": "text"
      },
      "source": [
        "## TOKENIZE DATASET AND FILTER WITH VOCAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CrrEj2sluJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn a doc into clean tokens\n",
        "def clean_txt_file(doc, vocab):\n",
        "\t# split into tokens by white space\n",
        "\ttokens = doc.split()\n",
        "\t# remove punctuation from each token\n",
        "\ttable = str.maketrans('', '', punctuation)\n",
        "\ttokens = [w.translate(table) for w in tokens]\n",
        "\t# filter out tokens not in vocab\n",
        "\ttokens = [w for w in tokens if w in vocab]\n",
        "\ttokens = ' '.join(tokens)\n",
        "\treturn tokens\n",
        "\n",
        "# load all files in a directory\n",
        "def process_txt_files(directory, vocab, is_train):\n",
        "\tdocuments = list()\n",
        "\t# walk through all files in the folder\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# skip any reviews in the test set\n",
        "\t\tif is_train and filename.startswith('cv9'):\n",
        "\t\t\tcontinue\n",
        "\t\tif not is_train and not filename.startswith('cv9'):\n",
        "\t\t\tcontinue\n",
        "\t\t# create the full path of the file to open\n",
        "\t\tpath = directory + '/' + filename\n",
        "\t\t# load the doc\n",
        "\t\tdoc = ReadFile(path)\n",
        "\t\t# clean doc\n",
        "\t\ttokens = clean_txt_file(doc, vocab)\n",
        "\t\t# add to list\n",
        "\t\tdocuments.append(tokens)\n",
        "\treturn documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wQ930uXl8yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "This block of code takes the positive and negative review text files and filters out\n",
        "the words that are not in the vocab.txt file\n",
        "'''\n",
        "\n",
        "with open('/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/vocab.txt', 'r') as f:\n",
        "  vocab_file = f.read()\n",
        "  vocab = vocab_file.split()\n",
        "  vocab = set(vocab)\n",
        "with open('/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/imdbvocab.txt', 'r') as f:\n",
        "  imdbVocab_file = f.read()\n",
        "  imdbVocab = imdbVocab_file.split()\n",
        "  imdbVocab = set(imdbVocab)\n",
        "\n",
        "\n",
        "neg_directory = '/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/neg'\n",
        "pos_directory = '/content/drive/My Drive/CS175/movie-review/movie_reviews/movie_reviews/pos'\n",
        "# load all training reviews\n",
        "positive_docs = process_txt_files(pos_directory, vocab, True)\n",
        "negative_docs = process_txt_files(neg_directory, vocab, True)\n",
        "\n",
        "imdb_docs = list()\n",
        "imdb_train_labels = list()\n",
        "for review in imdb_train:\n",
        "  tokens = clean_txt_file(review['text'].numpy().decode('utf-8'), imdbVocab)\n",
        "  imdb_docs.append(tokens)\n",
        "  imdb_train_labels.append(review['label'].numpy())\n",
        "imdb_train_labels = array(imdb_train_labels)\n",
        "\n",
        "train_docs = negative_docs + positive_docs\n",
        "# train_docs is the list of vocab words we use to train our model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wnEAhMInTtn",
        "colab_type": "text"
      },
      "source": [
        "We can now train a model using the positive and negative words acquired from the review text files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU1Ihp5JEpkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(train_docs)\n",
        "\n",
        "IMDBTokenizer = Tokenizer()\n",
        "\n",
        "IMDBTokenizer.fit_on_texts(imdb_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbv_6O0iz-AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sequence encode\n",
        "encoded_docs_train = tokenizer.texts_to_sequences(train_docs)\n",
        "imdb_encoded_train = IMDBTokenizer.texts_to_sequences(imdb_docs)\n",
        "\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_docs])\n",
        "Xtrain = pad_sequences(encoded_docs_train, maxlen=max_length, padding='post')\n",
        "ytrain = array([0 for i in range(900)] + [1 for i in range(900)])\n",
        "\n",
        "# pad sequences IMDB\n",
        "imdb_max_length = max([len(s.split()) for s in imdb_docs])\n",
        "imdbXtrain = pad_sequences(imdb_encoded_train, maxlen=imdb_max_length, padding='post')\n",
        "\n",
        "# load all test reviews\n",
        "positive_lines = process_txt_files(pos_directory, vocab, False)\n",
        "negative_lines = process_txt_files(neg_directory, vocab, False)\n",
        "\n",
        "imdb_test = tfds.load(name=\"imdb_reviews\", split=\"test\")\n",
        "imdb_test = imdb_test.shuffle(1024).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "imdb_testdocs = list()\n",
        "imdb_test_labels = list()\n",
        "for review in imdb_test:\n",
        "  tokens = clean_txt_file(review['text'].numpy().decode('utf-8'), imdbVocab)\n",
        "  imdb_testdocs.append(tokens)\n",
        "  imdb_test_labels.append(review['label'].numpy())\n",
        "imdb_test_labels = array(imdb_test_labels)\n",
        "\n",
        "test_docs = negative_lines + positive_lines\n",
        "\n",
        "encoded_docs_test = tokenizer.texts_to_sequences(test_docs)\n",
        "# pad sequences\n",
        "Xtest = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')\n",
        "ytest = array([0 for i in range(100)] + [1 for i in range(100)])\n",
        "\n",
        "# define vocabulary size (largest integer value)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "#IMDB\n",
        "imdb_encoded_docs_test = IMDBTokenizer.texts_to_sequences(imdb_testdocs)\n",
        "# pad sequences\n",
        "imdbXtest = pad_sequences(imdb_encoded_docs_test, maxlen=imdb_max_length, padding='post')\n",
        "\n",
        "\n",
        "# define vocabulary size (largest integer value)\n",
        "imdb_vocab_size = len(IMDBTokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSDuFFH9i0vX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNNModel = None\n",
        "RNNModelimdb = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhGSStXWZpUR",
        "colab_type": "text"
      },
      "source": [
        "After cleaning our tokens, we now create our neural networks to train and test on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEiNqTlHZ9qq",
        "colab_type": "text"
      },
      "source": [
        "## NEURAL NETWORKS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLIaMd5cu-D0",
        "colab_type": "code",
        "outputId": "2662dbbb-f96e-4365-9826-40abdbe637e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "'''\n",
        "Create the CNN model\n",
        "'''\n",
        "CNNmodel = tf.keras.Sequential()\n",
        "CNNmodel.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
        "#model.add(Dropout(0.2))\n",
        "CNNmodel.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "CNNmodel.add(MaxPooling1D(pool_size=3))\n",
        "CNNmodel.add(Flatten())\n",
        "CNNmodel.add(Dense(15, activation='relu')) # can increase the amount of units\n",
        "CNNmodel.add(Dense(1, activation='sigmoid'))\n",
        "print(CNNmodel.summary())\n",
        "\n",
        "# compile network\n",
        "CNNmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "CNNmodel.fit(Xtrain, ytrain, epochs=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 942, 100)          1060800   \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 935, 32)           25632     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 311, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 9952)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 15)                149295    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 1,235,743\n",
            "Trainable params: 1,235,743\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1800 samples\n",
            "Epoch 1/10\n",
            "1800/1800 - 9s - loss: 0.6894 - accuracy: 0.5289\n",
            "Epoch 2/10\n",
            "1800/1800 - 1s - loss: 0.6222 - accuracy: 0.6600\n",
            "Epoch 3/10\n",
            "1800/1800 - 1s - loss: 0.2847 - accuracy: 0.8967\n",
            "Epoch 4/10\n",
            "1800/1800 - 1s - loss: 0.0503 - accuracy: 0.9922\n",
            "Epoch 5/10\n",
            "1800/1800 - 1s - loss: 0.0089 - accuracy: 0.9994\n",
            "Epoch 6/10\n",
            "1800/1800 - 1s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1800/1800 - 1s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1800/1800 - 1s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1800/1800 - 1s - loss: 7.7655e-04 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1800/1800 - 1s - loss: 5.7451e-04 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d71f2c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_FPEDfAcrA3",
        "colab_type": "code",
        "outputId": "2fa95320-feda-4dee-ea63-cd4c6f27c55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "CNNmodelimdb = tf.keras.Sequential()\n",
        "CNNmodelimdb.add(Embedding(input_dim=imdb_vocab_size, output_dim=100, input_length=imdb_max_length))\n",
        "#model.add(Dropout(0.2))\n",
        "CNNmodelimdb.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
        "CNNmodelimdb.add(MaxPooling1D(pool_size=3))\n",
        "CNNmodelimdb.add(Flatten())\n",
        "CNNmodelimdb.add(Dense(15, activation='relu')) # can increase the amount of units\n",
        "CNNmodelimdb.add(Dense(1, activation='sigmoid'))\n",
        "print(CNNmodelimdb.summary())\n",
        "\n",
        "# compile network\n",
        "CNNmodelimdb.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit network\n",
        "CNNmodelimdb.fit(imdbXtrain, imdb_train_labels, epochs=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 1347, 100)         1681700   \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 1340, 32)          25632     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 446, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 14272)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 15)                214095    \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 1,921,443\n",
            "Trainable params: 1,921,443\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 - 20s - loss: 0.4625 - accuracy: 0.7659\n",
            "Epoch 2/10\n",
            "25000/25000 - 20s - loss: 0.2918 - accuracy: 0.8774\n",
            "Epoch 3/10\n",
            "25000/25000 - 20s - loss: 0.2008 - accuracy: 0.9219\n",
            "Epoch 4/10\n",
            "25000/25000 - 19s - loss: 0.1063 - accuracy: 0.9627\n",
            "Epoch 5/10\n",
            "25000/25000 - 19s - loss: 0.0378 - accuracy: 0.9898\n",
            "Epoch 6/10\n",
            "25000/25000 - 20s - loss: 0.0133 - accuracy: 0.9968\n",
            "Epoch 7/10\n",
            "25000/25000 - 20s - loss: 0.0071 - accuracy: 0.9981\n",
            "Epoch 8/10\n",
            "25000/25000 - 19s - loss: 0.0167 - accuracy: 0.9947\n",
            "Epoch 9/10\n",
            "25000/25000 - 20s - loss: 0.0129 - accuracy: 0.9959\n",
            "Epoch 10/10\n",
            "25000/25000 - 20s - loss: 0.0026 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d727cc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDHlt_H0FQoi",
        "colab_type": "code",
        "outputId": "1b5e1df9-1e4a-497a-a1e7-80c1d03781c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"\n",
        "GloVe embedding (pre-trained word embedding)\n",
        "\"\"\"\n",
        "\n",
        "#load embedding into memory\n",
        "embedding_indexes = dict()\n",
        "f = open('/content/drive/My Drive/CS175/movie-review/glove_embeddings/glove.6B.100d.txt')\n",
        "for l in f:\n",
        "  v = l.split()\n",
        "  c = asarray(v[1:], dtype='float32')\n",
        "  embedding_indexes[v[0]] = c\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embedding_indexes))\n",
        "\n",
        "#create weight matrix\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for w, i in tokenizer.word_index.items():\n",
        "  vector = embedding_indexes.get(w)\n",
        "  if vector is not None:\n",
        "    embedding_matrix[i] = vector\n",
        "\n",
        "#define model\n",
        "GloveModel = tf.keras.Sequential()\n",
        "GloveModel.add(Embedding(vocab_size, output_dim=100, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "GloveModel.add(Flatten())\n",
        "GloveModel.add(Dense(15, activation='relu'))\n",
        "GloveModel.add(Dense(1, activation='sigmoid'))\n",
        "GloveModel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(GloveModel.summary())\n",
        "\n",
        "# fit model\n",
        "GloveModel.fit(Xtrain, ytrain, epochs=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 942, 100)          1060800   \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 94200)             0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 15)                1413015   \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 2,473,831\n",
            "Trainable params: 1,413,031\n",
            "Non-trainable params: 1,060,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1800 samples\n",
            "Epoch 1/10\n",
            "1800/1800 - 1s - loss: 0.7333 - accuracy: 0.5172\n",
            "Epoch 2/10\n",
            "1800/1800 - 0s - loss: 0.6189 - accuracy: 0.6372\n",
            "Epoch 3/10\n",
            "1800/1800 - 0s - loss: 0.3803 - accuracy: 0.8489\n",
            "Epoch 4/10\n",
            "1800/1800 - 0s - loss: 0.1608 - accuracy: 0.9817\n",
            "Epoch 5/10\n",
            "1800/1800 - 0s - loss: 0.0804 - accuracy: 0.9950\n",
            "Epoch 6/10\n",
            "1800/1800 - 0s - loss: 0.0487 - accuracy: 0.9989\n",
            "Epoch 7/10\n",
            "1800/1800 - 0s - loss: 0.0307 - accuracy: 0.9994\n",
            "Epoch 8/10\n",
            "1800/1800 - 0s - loss: 0.0202 - accuracy: 0.9994\n",
            "Epoch 9/10\n",
            "1800/1800 - 0s - loss: 0.0150 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1800/1800 - 0s - loss: 0.0113 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6aa07e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 942, 100)          1060800   \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 94200)             0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 15)                1413015   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 2,473,831\n",
            "Trainable params: 1,413,031\n",
            "Non-trainable params: 1,060,800\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1800 samples\n",
            "Epoch 1/10\n",
            "1800/1800 - 1s - loss: 0.7118 - accuracy: 0.5072\n",
            "Epoch 2/10\n",
            "1800/1800 - 0s - loss: 0.6812 - accuracy: 0.4978\n",
            "Epoch 3/10\n",
            "1800/1800 - 0s - loss: 0.6299 - accuracy: 0.6217\n",
            "Epoch 4/10\n",
            "1800/1800 - 0s - loss: 0.5415 - accuracy: 0.6822\n",
            "Epoch 5/10\n",
            "1800/1800 - 0s - loss: 0.2786 - accuracy: 0.9000\n",
            "Epoch 6/10\n",
            "1800/1800 - 0s - loss: 0.1310 - accuracy: 0.9739\n",
            "Epoch 7/10\n",
            "1800/1800 - 0s - loss: 0.0523 - accuracy: 0.9883\n",
            "Epoch 8/10\n",
            "1800/1800 - 0s - loss: 0.0188 - accuracy: 0.9994\n",
            "Epoch 9/10\n",
            "1800/1800 - 0s - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1800/1800 - 0s - loss: 0.0088 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6a8717160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqmxe-ySpw-Q",
        "colab_type": "code",
        "outputId": "51be704a-2bf1-4205-d743-c343cd7e1eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "#create weight matrix\n",
        "\n",
        "embedding_matrix_imdb = zeros((imdb_vocab_size, 100))\n",
        "for w, i in IMDBTokenizer.word_index.items():\n",
        "  vector = embedding_indexes.get(w)\n",
        "  if vector is not None:\n",
        "    embedding_matrix_imdb[i] = vector\n",
        "\n",
        "#define model\n",
        "GloveModelimdb = tf.keras.Sequential()\n",
        "GloveModelimdb.add(Embedding(imdb_vocab_size, output_dim=100, weights=[embedding_matrix_imdb], input_length=imdb_max_length, trainable=False))\n",
        "GloveModelimdb.add(Flatten())\n",
        "GloveModelimdb.add(Dense(15, activation='relu'))\n",
        "GloveModelimdb.add(Dense(1, activation='sigmoid'))\n",
        "GloveModelimdb.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(GloveModelimdb.summary())\n",
        "\n",
        "# fit model\n",
        "GloveModelimdb.fit(imdbXtrain, imdb_train_labels, epochs=10, verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 1347, 100)         1681700   \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 134700)            0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 15)                2020515   \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 3,702,231\n",
            "Trainable params: 2,020,531\n",
            "Non-trainable params: 1,681,700\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 - 5s - loss: 0.6959 - accuracy: 0.4972\n",
            "Epoch 2/10\n",
            "25000/25000 - 4s - loss: 0.6932 - accuracy: 0.4988\n",
            "Epoch 3/10\n",
            "25000/25000 - 4s - loss: 0.6932 - accuracy: 0.4965\n",
            "Epoch 4/10\n",
            "25000/25000 - 4s - loss: 0.6931 - accuracy: 0.5012\n",
            "Epoch 5/10\n",
            "25000/25000 - 4s - loss: 0.6931 - accuracy: 0.4972\n",
            "Epoch 6/10\n",
            "25000/25000 - 4s - loss: 0.6931 - accuracy: 0.4988\n",
            "Epoch 7/10\n",
            "25000/25000 - 4s - loss: 0.6928 - accuracy: 0.4998\n",
            "Epoch 8/10\n",
            "25000/25000 - 4s - loss: 0.6925 - accuracy: 0.4982\n",
            "Epoch 9/10\n",
            "25000/25000 - 4s - loss: 0.6919 - accuracy: 0.5034\n",
            "Epoch 10/10\n",
            "25000/25000 - 4s - loss: 0.6903 - accuracy: 0.5124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6a85eb2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8EOoEk76k1a",
        "colab_type": "code",
        "outputId": "38802a6f-5321-449b-e24e-b55ba8bf1960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "# https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
        "\n",
        "RNNModel = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=imdb_vocab_size, output_dim=100, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "RNNModel.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(RNNModel.summary())\n",
        "\n",
        "# history = RNNModel.fit(Xtrain, epochs=10,\n",
        "#                     validation_data=ytrain,\n",
        "#                     validation_steps=30)\n",
        "\n",
        "RNNModel.fit(Xtrain, ytrain, epochs=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 942, 100)          1681700   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 942, 128)          84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,811,621\n",
            "Trainable params: 1,811,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1800 samples\n",
            "Epoch 1/10\n",
            "1800/1800 - 11s - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1800/1800 - 7s - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1800/1800 - 7s - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1800/1800 - 7s - loss: 0.6876 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1800/1800 - 7s - loss: 0.6205 - accuracy: 0.5756\n",
            "Epoch 6/10\n",
            "1800/1800 - 7s - loss: 0.3734 - accuracy: 0.8378\n",
            "Epoch 7/10\n",
            "1800/1800 - 7s - loss: 0.2098 - accuracy: 0.9317\n",
            "Epoch 8/10\n",
            "1800/1800 - 7s - loss: 0.1027 - accuracy: 0.9739\n",
            "Epoch 9/10\n",
            "1800/1800 - 7s - loss: 0.0534 - accuracy: 0.9889\n",
            "Epoch 10/10\n",
            "1800/1800 - 7s - loss: 0.0415 - accuracy: 0.9944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6d75234a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBLLAnuT1ap",
        "colab_type": "code",
        "outputId": "fbd3250a-87e3-45d2-f8cb-67b01e8452e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "source": [
        "RNNModelimdb = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=imdb_vocab_size, output_dim=100, input_length=imdb_max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "RNNModelimdb.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "RNNModelimdb.summary()\n",
        "\n",
        "RNNModelimdb.fit(imdbXtrain, imdb_train_labels, epochs=10, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 1347, 100)         1681700   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 1347, 128)         84480     \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,811,621\n",
            "Trainable params: 1,811,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 - 136s - loss: 0.5737 - accuracy: 0.6569\n",
            "Epoch 2/10\n",
            "25000/25000 - 130s - loss: 0.3821 - accuracy: 0.8398\n",
            "Epoch 3/10\n",
            "25000/25000 - 128s - loss: 0.3266 - accuracy: 0.8704\n",
            "Epoch 4/10\n",
            "25000/25000 - 130s - loss: 0.2832 - accuracy: 0.8926\n",
            "Epoch 5/10\n",
            "25000/25000 - 133s - loss: 0.2588 - accuracy: 0.9058\n",
            "Epoch 6/10\n",
            "25000/25000 - 133s - loss: 0.2263 - accuracy: 0.9192\n",
            "Epoch 7/10\n",
            "25000/25000 - 133s - loss: 0.2057 - accuracy: 0.9290\n",
            "Epoch 8/10\n",
            "25000/25000 - 133s - loss: 0.1845 - accuracy: 0.9382\n",
            "Epoch 9/10\n",
            "25000/25000 - 132s - loss: 0.1643 - accuracy: 0.9463\n",
            "Epoch 10/10\n",
            "25000/25000 - 132s - loss: 0.1516 - accuracy: 0.9507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd69924fd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zHvBcjsZE2h",
        "colab_type": "text"
      },
      "source": [
        "Saving our RNNs for use later because it takes a while to train, so we don't want to keep re-training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CqckpN6p0bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNNModel.save('/content/drive/My Drive/CS175/RNNmodel.h5')\n",
        "RNNModelimdb.save('/content/drive/My Drive/CS175/RNNmodelimdb.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vibF2jDibERr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RNNModel == None:\n",
        "  RNNModel = load_model('/content/drive/My Drive/CS175/RNNmodel.h5')\n",
        "if RNNModelimdb == None:\n",
        "  RNNModelimdb = load_model('/content/drive/My Drive/CS175/RNNmodelimdb.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4JxIqndfbUW",
        "colab_type": "text"
      },
      "source": [
        "## EVALUATE SCORES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRvMKvhcLgVw",
        "colab_type": "text"
      },
      "source": [
        "Here we use the accuracy function to determine how well each neural network does. The higher the accuracy, the better the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJXmRXlhJ_tx",
        "colab_type": "code",
        "outputId": "5097a9a5-3784-4032-984b-e14da1e15548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "loss_cnnk, acc_cnnk = CNNmodel.evaluate(Xtest, ytest, verbose=0)\n",
        "acc_cnnk = round(acc_cnnk*100, 2)\n",
        "print('Test Loss CNN Kaggle: {}'.format(loss_cnnk))\n",
        "print('Test Accuracy CNN Kaggle: {}%'.format(acc_cnnk))\n",
        "print()\n",
        "\n",
        "loss_cnnimdb, acc_cnnimdb = CNNmodelimdb.evaluate(imdbXtest, imdb_test_labels, verbose=0)\n",
        "acc_cnnimdb = round(acc_cnnimdb*100, 2)\n",
        "print('Test Loss CNN IMDB: {}'.format(loss_cnnimdb))\n",
        "print('Test Accuracy CNN IMDB: {}%'.format(acc_cnnimdb))\n",
        "print()\n",
        "\n",
        "loss_gk, acc_gk = GloveModel.evaluate(Xtest, ytest, verbose=0)\n",
        "acc_gk = round(acc_gk*100, 2)\n",
        "print('Test Loss GloVe Kaggle: {}'.format(loss_gk))\n",
        "print('Test Accuracy GloVe Kaggle: {}%'.format(acc_gk))\n",
        "print()\n",
        "\n",
        "loss_gimdb, acc_gimdb = GloveModelimdb.evaluate(imdbXtest, imdb_test_labels, verbose=0)\n",
        "acc_gimdb = round(acc_gimdb*100, 2)\n",
        "print('Test Loss GloVe IMDB: {}'.format(loss_gimdb))\n",
        "print('Test Accuracy GloVe IMDB: {}%'.format(acc_gimdb))\n",
        "print()\n",
        "\n",
        "loss_rnnk, acc_rnnk = RNNModel.evaluate(Xtest, ytest, verbose=0)\n",
        "acc_rnnk = round(acc_rnnk*100, 2)\n",
        "print('Test Loss RNN Kaggle: {}%'.format(loss_rnnk))\n",
        "print('Test Accuracy RNN Kaggle: {}%'.format(acc_rnnk))\n",
        "print()\n",
        "\n",
        "loss_rnnimdb, acc_rnnimdb = RNNModelimdb.evaluate(imdbXtest, imdb_test_labels, verbose=0)\n",
        "acc_rnnimdb = round(acc_rnnimdb*100, 2)\n",
        "print('Test Loss RNN IMDB: {}'.format(loss_rnnimdb))\n",
        "print('Test Accuracy RNN IMDB: {}%'.format(acc_rnnimdb))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss CNN Kaggle: 0.7431644535064698\n",
            "Test Accuracy CNN Kaggle: 78.5%\n",
            "\n",
            "Test Loss CNN IMDB: 1.3818824168777466\n",
            "Test Accuracy CNN IMDB: 80.98%\n",
            "\n",
            "Test Loss GloVe Kaggle: 1.0044598722457885\n",
            "Test Accuracy GloVe Kaggle: 56.5%\n",
            "\n",
            "Test Loss GloVe IMDB: 0.6905522338867187\n",
            "Test Accuracy GloVe IMDB: 51.59%\n",
            "\n",
            "Test Loss RNN Kaggle: 0.7675459694862365%\n",
            "Test Accuracy RNN Kaggle: 77.5%\n",
            "\n",
            "Test Loss RNN IMDB: 0.6009780989599228\n",
            "Test Accuracy RNN IMDB: 80.81%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khgy3sasY2CK",
        "colab_type": "text"
      },
      "source": [
        "Here we test our RNN trained on the Kaggle dataset with the IMDB test set and \n",
        "test our RNN trained on IMDB dataset on the Kaggle test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAuzThwHkSx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle_test_list = pad_sequences(encoded_docs_test, maxlen=imdb_max_length, padding='post')\n",
        "kaggle_label_test = array([0 for i in range(100)] + [1 for i in range(100)])\n",
        "\n",
        "imdb_test_list = pad_sequences(imdb_encoded_docs_test, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqQy66soIEZ",
        "colab_type": "code",
        "outputId": "fcf92ac4-35df-4c7a-9398-b85dfda741cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "kag_test_loss, kag_test_acc = RNNModel.evaluate(imdb_test_list, imdb_test_labels, verbose = 0)\n",
        "kag_test_acc = round(kag_test_acc*100, 2)\n",
        "print('Test Loss RNN Kaggle on IMDB: {}'.format(kag_test_loss))\n",
        "print('Test Accuracy RNN Kaggle on IMDB: {}%'.format(kag_test_acc))\n",
        "print()\n",
        "\n",
        "imdb_test_loss, imdb_test_acc = RNNModelimdb.evaluate(kaggle_test_list, kaggle_label_test, verbose=0)\n",
        "imdb_test_acc = round(imdb_test_acc*100, 2)\n",
        "print('Test Loss RNN IMDB on Kaggle: {}'.format(imdb_test_loss))\n",
        "print('Test Accuracy RNN IMDB on Kaggle: {}%'.format(imdb_test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss RNN Kaggle on IMDB: 1.5687851857757569\n",
            "Test Accuracy RNN Kaggle on IMDB: 51.55%\n",
            "\n",
            "Test Loss RNN IMDB on Kaggle: 2.2632213592529298\n",
            "Test Accuracy RNN IMDB on Kaggle: 49.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_gTRmQKIlor",
        "colab_type": "code",
        "outputId": "100a0b41-64ec-4102-cdf9-f269e6d52f42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "labels = [\"CNN\", \"Neural Net with GloVe\", \"RNN LSTM\"]\n",
        "kaggle_data = [acc_cnnk, acc_gk, acc_rnnk]\n",
        "imdb_data = [acc_cnnimdb, acc_gimdb, acc_rnnimdb]\n",
        "\n",
        "x = np.arange(len(labels))\n",
        "width = 0.3\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_ylim(0,110)\n",
        "#fig.set_figheight(7)\n",
        "#fig.set_figwidth(7)\n",
        "rects1 = ax.bar(x - width/2, kaggle_data, width, label='Kaggle_Dataset')\n",
        "rects2 = ax.bar(x + width/2, imdb_data, width, label='IMDB_dataset')\n",
        "\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('Movie Review Results')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "def autolabel(rects):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate('{}'.format(height),\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUFJAiYhIKP3/lH0cFEM+gpsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm0w8-EuJYUP",
        "colab_type": "code",
        "outputId": "bc2a62ba-2fec-4202-bd78-6a8409d2c0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "x = [0,.6]\n",
        "y = [kag_test_acc, imdb_test_acc]\n",
        "labels = ['RNN trained on Kaggle Dataset', 'RNN trained on IMDB Dataset']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_ylim(0,100)\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.set_title('RNN trained on one dataset and tested on another')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "\n",
        "rects = ax.bar(x, y, .5)\n",
        "\n",
        "autolabel(rects)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}